# -*- coding: utf-8 -*-
"""577_final_project_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QUjbMsQi9aguc8XybuuvS3Qns8FxOi2d
"""

!pip install catboost
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from catboost import Pool, CatBoostClassifier

!pip install -q feature_engine autoviz dataprep 2>/dev/null

df= pd.read_csv('Crime_Data_from_2020_to_Present.csv')

df.head()

df.dtypes

df.describe()
# HERE, WE CAN ALSO OBSERVE THAT MEAN VICTIM AGE IS 30 YEARS.

df.isnull().sum()
# As we can see we have very high missing values

df.duplicated().sum()
# we have 0 duplicate values.

# dropping unecessary columns
df.drop(['LAT','LON'],axis=1,inplace=True)
df.drop(['Cross Street'],axis=1,inplace=True)
df.drop(['Premis Desc'],axis=1,inplace=True)
list(df.columns)

df.shape

df['Date Rptd']= pd.to_datetime(df['Date Rptd'])
df['DATE OCC'] = pd.to_datetime(df['DATE OCC'])

df['Crm Cd 1'].mean()

df['Crm Cd 1'].fillna(506.13172700382023,inplace=True)

df['Crm Cd 2'].mean()

df['Crm Cd 2'].fillna(957.8200653318008,inplace=True)

df['Crm Cd 3'].mean()

df['Crm Cd 3'].fillna(983.9938271604939,inplace=True)

df['Crm Cd 4'].mean()

df['Crm Cd 4'].fillna(990.5142857142857,inplace=True)

df['Weapon Used Cd'].mean()

df['Weapon Used Cd'].fillna(362.13985242811884,inplace=True)

df['Mocodes'].fillna('Unknown',inplace=True)
df['Vict Sex'].fillna('Unknown',inplace=True)
df['Vict Descent'].fillna('Unknown',inplace=True)
df['Weapon Desc'].fillna('Unknown',inplace=True)
df['Premis Cd'].fillna('Unknown',inplace=True)
df['Status Desc'].fillna('Unknown',inplace=True)
df['Status'].fillna('Unknown',inplace=True)
df['LOCATION'].fillna('Unknown',inplace=True)

df.isnull().sum()

df['Year'] = df['DATE OCC'].dt.year
df['Year'].value_counts()

df['Year_rptd']= df['Date Rptd'].dt.year
df['Year_rptd'].value_counts()

#Which month had the highest number of reported crimes in 2023?
df['Month'] = df['Date Rptd'].dt.strftime('%B')

plt.figure(figsize=(12,5))
ax=sns.countplot(x=df['Month'].sort_values(),data=df['Date Rptd'].dt.year==2023)

for bars in ax.containers:
    ax.bar_label(bars)

plt.title('Crimes reported monthwise in year 2023')
plt.ylabel('')
plt.show()

#How has the distribution of crime types evolved over the past three years?
end_date = pd.Timestamp.now()
start_date = end_date - pd.DateOffset(years=3)
filtered_data = df[(df['DATE OCC'] >= start_date) & (df['DATE OCC'] <= end_date)]


crime_type_counts = filtered_data.groupby([filtered_data['DATE OCC'].dt.year,'Crm Cd Desc']).size().unstack(fill_value=0)
top_5_crime_types = crime_type_counts.sum().sort_values(ascending=False).head(5).index
crime_type_counts_top_5 = crime_type_counts[top_5_crime_types]

plt.figure(figsize=(15,8))
crime_type_counts_top_5.plot(kind='line', marker='o', legend=False)
plt.xlabel('Year-Month')
plt.ylabel('Crime Count')
plt.title('Crime Type Evolution Over the Last 3 Years')
plt.legend(title='Crime Type', prop={'size': 4})
plt.xticks(rotation=45)
plt.show()

df['Crm Cd Desc'].value_counts()[:10]

import textwrap
plt.figure(figsize=(12,5))
vc=df['Crm Cd Desc'].value_counts()[:10]

wrapped_labels = [textwrap.fill(label, width=15) for label in vc.index]

g= sns.barplot(x=wrapped_labels, y= vc.values, data=df,palette='rocket')

for i in range(10):
    value=vc[i]
    g.text(x=i +0.125,y=value-2, s= value,ha='center')


plt.title('Most Common Top 10 Crimes')
plt.xticks(rotation=60)
plt.show()

# Identify neighborhoods with above-average crime rates

neighborhood_crime_counts = df['AREA NAME'].value_counts()
average_crime_per_neighborhood = neighborhood_crime_counts.mean()
high_crime_neighborhoods = neighborhood_crime_counts[neighborhood_crime_counts > average_crime_per_neighborhood]

print("Neighborhoods with Above-Average Crime Rates:")
print(high_crime_neighborhoods)

# Here we can see central LA,77th Street,Pacific Top three neighborhood have above average-crime rate

plt.figure(figsize=(12,5))
sns.barplot(x=high_crime_neighborhoods.index, y=high_crime_neighborhoods.values, data=df,palette='rocket')

plt.title('Neighborhoods with Above-Average Crime Rates')
plt.show()

df['Status Desc'].value_counts()

Status_type_counts = df.groupby([df['Year'],'Status Desc']).size().unstack(fill_value=0)

plt.figure(figsize=(15,8))
Status_type_counts.plot(kind='line', marker='o', legend=False)
plt.xlabel('Year-Month')
plt.ylabel('')
plt.title('Evolution of Status Over the Past Three Years')
plt.legend(title='Status', prop={'size': 6})
plt.xticks(rotation=45)
plt.show()

# Explore crime distribution by time
plt.figure(figsize=(12, 6))
sns.histplot(data=df, x='TIME OCC', bins=24, kde=True, color='blue')
plt.title('Distribution of Crimes by Time of Day')
plt.xlabel('Time (24-hour format)')
plt.ylabel('Number of Crimes')
plt.show()

df.head(10)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

#df = df.drop(['Month', 'Year', 'Year_rptd'],axis=1)
# Assuming df is your DataFrame
correlation_matrix = df.corr()

# Plot the correlation heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

import numpy as np  # Import NumPy for numerical operations
import pandas as pd  # Import Pandas for data manipulation and analysis

import warnings  # Import the warnings module to handle warnings
warnings.filterwarnings("ignore")  # Filter and suppress warnings

# Import AutoViz_Class for automated visualization
from autoviz import AutoViz_Class

# Import load_dataset and create_report from dataprep for data loading and exploratory data analysis
from dataprep.datasets import load_dataset
from dataprep.eda import create_report



# Import CountVectorizer for text feature extraction
from sklearn.feature_extraction.text import CountVectorizer

# Import RareLabelEncoder for encoding categorical variables with rare labels
from feature_engine.encoding import RareLabelEncoder

# Import metrics for model evaluation
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, f1_score

# Import train_test_split for data splitting
from sklearn.model_selection import train_test_split

# Import Seaborn for advanced visualization
import seaborn as sns

# Import itertools for various iteration-related tasks
import itertools

# Set Pandas options to display a maximum of 1000 rows
pd.set_option('display.max_rows', 1000)

df0 = pd.read_csv('Crime_Data_from_2020_to_Present.csv')
df1 = pd.read_csv('Crime_Data_from_2020_to_Present.csv')
df2 = pd.read_csv('Crime_Data_from_2020_to_Present.csv')
df3 = pd.read_csv('Crime_Data_from_2020_to_Present.csv')
df4 = pd.read_csv('Crime_Data_from_2020_to_Present.csv')
print(df0.shape, df1.shape, df2.shape, df3.shape, df4.shape)
print(df0.columns, df1.columns, df2.columns, df3.columns, df4.columns)

# Concatenate the dataframes and drop duplicates
df = pd.concat([df0, df1, df2, df3, df4], axis=0).drop_duplicates()
# Print the shape of the DataFrame to show the number of rows and columns
print(df.shape)

# Display a random sample of 5 rows of the DataFrame, transposed for better visibility
df.sample(5).T

# Select 'Status Desc' as the main label and convert it to binary (1 for 'Adust Arrest' and 'Juv Arrest', 0 otherwise)
main_label = 'Status Desc'
df[main_label] = (df[main_label].isin(['Adust Arrest', 'Juv Arrest'])).astype(int)

# Extract the year from the 'DATE OCC' column
df['Year'] = df['DATE OCC'].apply(lambda x: x[6:10])

# Group victim ages into intervals of 5 years
df['Vict Age'] = df['Vict Age'].apply(lambda x: 5 * round(1/5 * x))

# Set up a rare label encoder for categorical columns, limiting the number of categories and replacing rare ones with 'Other'
for col in ['AREA NAME', 'Crm Cd Desc', 'Vict Sex', 'Vict Descent', 'Premis Desc', 'Weapon Desc']:
    df[col] = df[col].fillna('None')  # Fill missing values with 'None'
    encoder = RareLabelEncoder(n_categories=1, max_n_categories=70, replace_with='Other', tol=20/df.shape[0])
    df[col] = encoder.fit_transform(df[[col]])

# Drop unused columns from the DataFrame
cols2drop = ['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Mocodes',
             'Premis Cd', 'Weapon Used Cd', 'Status', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'Cross Street',
             'LAT', 'LON', 'LOCATION']
df = df.drop(cols2drop, axis=1)

# Print the shape of the DataFrame and display a random sample of 5 rows (transposed for readability)
print(df.shape)
df.sample(5).T

# Import necessary libraries and modules
import pandas as pd  # Assuming 'pd' is imported elsewhere in your code
from sklearn.model_selection import train_test_split

# Extract the target variable 'main_label' and features from the DataFrame 'df'
y = df[main_label].values.reshape(-1,)  # Reshape the target variable as a 1D array
X = df.drop([main_label], axis=1)  # Create the feature matrix by excluding the target variable

# Identify categorical columns in the feature matrix 'X'
cat_cols = df.select_dtypes(include=['object']).columns

# Get the indices of categorical columns in the feature matrix 'X'
cat_cols_idx = [list(X.columns).index(c) for c in cat_cols]

# Split the data into training and testing sets, stratified by 'y' for balanced class distribution
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)

# Print the shapes of the resulting data splits
print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

# Import the necessary library to compute class weights.
from sklearn.utils.class_weight import compute_class_weight

# Identify the unique classes in the training data.
classes = np.unique(y_train)

# Calculate class weights using the 'balanced' option, which automatically adjusts for class imbalance.
weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)

# Create a dictionary mapping each class to its respective class weight.
class_weights = dict(zip(classes, weights))

# Print the computed class weights to the console.
print(class_weights)

## Initialize Pools for training and testing data, specifying categorical features
train_pool = Pool(X_train,
                  y_train,
                  cat_features=cat_cols_idx)
test_pool = Pool(X_test,
                 y_test,
                 cat_features=cat_cols_idx)

# Specify the training parameters for the CatBoostClassifier
model = CatBoostClassifier(iterations=200,   # Number of boosting iterations
                           depth=3,          # Depth of each tree in the ensemble
                           border_count=22,  # Number of splits for numerical features
                           l2_leaf_reg=0.3,  # L2 regularization strength
                           learning_rate=2e-1, # Learning rate for gradient descent
                           class_weights=class_weights,  # Weights for class balancing
                           early_stopping_rounds=10, # Early stopping rounds
                           verbose=0)        # Control the verbosity of training

# Train the model using the training data
model.fit(train_pool, eval_set=test_pool)

# Make predictions using the resulting trained model for both training and testing data
y_train_pred = model.predict_proba(train_pool)[:, 1]  # Predicted probabilities for training data
y_test_pred = model.predict_proba(test_pool)[:, 1]    # Predicted probabilities for testing data

# Calculate the ROC AUC score for both training and testing data
roc_auc_train = roc_auc_score(y_train, y_train_pred)  # ROC AUC score for training data
roc_auc_test = roc_auc_score(y_test, y_test_pred)     # ROC AUC score for testing data

# Print the ROC AUC scores for the training and testing data
print(f"ROC AUC score for train {round(roc_auc_train, 4)}, and for test {round(roc_auc_test, 4)}")

# calculating the baseline ROC AUC score assuming the same probability from training labels to test
roc_auc_baseline = roc_auc_score(y_test, [np.mean(y_train)]*len(y_test))
print(roc_auc_baseline)

# Manually selecting threshold to maximize test F1 score, see below
threshold = 0.94

# Define a function to plot the confusion matrix
def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):
    """
    This function plots a confusion matrix.

    Parameters:
        cm (array-like): Confusion matrix as returned by sklearn.metrics.confusion_matrix.
        classes (list): List of class names, e.g., ['Class 0', 'Class 1'].
        title (str): Title for the plot.
        cmap (matplotlib colormap): Colormap for the plot.
    """
    # Display the confusion matrix as an image
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    # Set labels and tick marks for the matrix
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    # Add text annotations for each cell in the matrix
    fmt = '.0f'
    thresh = cm.max() / 2.0
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()
    plt.show()

# Calculate accuracy and F1 score using the selected threshold
accuracy = accuracy_score(y_test, (y_test_pred > threshold))
f1 = f1_score(y_test, (y_test_pred > threshold))

# Display the selected threshold, accuracy, and F1 score
print(f"Selected threshold to maximize F1: {threshold}")
print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")

# Get the confusion matrix
cm = confusion_matrix(y_test, (y_test_pred > threshold))

# Plot the confusion matrix
class_names = ['Not Arrest', 'Arrest']  # Positive class should come last
plot_confusion_matrix(cm, class_names)

# Finally, display the classification report
print()
print("Classification report:")
print()
print(classification_report(y_test, (y_test_pred > threshold), target_names=class_names, digits=4))

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report

# Load your dataset
# Assuming your dataset is in a CSV file named 'crime_data.csv'
crime_data = pd.read_csv('Crime_Data_from_2020_to_Present.csv')

# Select features (X) and target variable (y)
features = ['Vict Age', 'Vict Sex', 'Vict Descent', 'Premis Cd', 'Weapon Used Cd']
target = 'Crm Cd Desc'
print(features)

X = crime_data[features]
y = crime_data[target]

# Handle categorical variables
imputer = SimpleImputer(strategy='most_frequent')
X = pd.get_dummies(X)
X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the decision tree model
model = DecisionTreeClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy_dt = accuracy_score(y_test, y_pred)
report_dt = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy_dt:.2f}\n')
print('Classification Report:\n', report_dt)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Downsample the data
# Specify the fraction of the data you want to keep (e.g., 0.1 for 10%)
fraction_to_keep = 0.1

X_downsampled, _, y_downsampled, _ = train_test_split(X, y, test_size=1 - fraction_to_keep, random_state=42)

# Split the downsampled data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_downsampled, y_downsampled, test_size=0.2, random_state=42)

# Initialize the Random Forest model
rf_model = RandomForestClassifier(random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(X_test)

# Evaluate the model
accuracy_rf = accuracy_score(y_test, y_pred)
report_rf = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy_rf:.2f}\n')
print('Classification Report:\n', report_rf)

from sklearn.svm import SVC

# Initialize the SVM model
svm_model = SVC(random_state=42)

# Train the model
svm_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm_model.predict(X_test)

# Evaluate the model
accuracy_svm = accuracy_score(y_test, y_pred)
report_svm = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy_svm:.2f}\n')
print('Classification Report:\n', report_svm)

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report

# Initialize the Gradient Boosting model
gb_model = GradientBoostingClassifier(random_state=42)

# Train the model
gb_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = gb_model.predict(X_test)

# Evaluate the model
accuracy_gb = accuracy_score(y_test, y_pred)
report_gb = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy_gb:.2f}\n')
print('Classification Report:\n', report_gb)

# Display results
print("Decision Tree Model:")
print(f'Accuracy: {accuracy_dt:.2f}\n')
print("---------------")

print("Random Forest Model:")
print(f'Accuracy: {accuracy_rf:.2f}\n')
print("---------------")

print("Support Vector Machine (SVM) Model:")
print(f'Accuracy: {accuracy_svm:.2f}\n')
print("---------------")

print("Gradient Boosting Model:")
print(f'Accuracy: {accuracy_gb:.2f}\n')